#!/usr/bin/env python3
"""
Japanese IME Training Data Generator
Creates training data specifically for Japanese keyboard IME behavior.
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple
from collections import defaultdict

class JapaneseIMEDataGenerator:
    """Generate IME-specific training data"""
    
    def __init__(self):
        self.data_dir = Path('data/japanese')
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Romaji to Hiragana mapping
        self.romaji_map = self.create_romaji_map()
        
        # Training examples
        self.examples = []
        
    def create_romaji_map(self) -> Dict[str, str]:
        """Create comprehensive romaji to hiragana mapping"""
        return {
            # Vowels
            'a': 'ã‚', 'i': 'ã„', 'u': 'ã†', 'e': 'ãˆ', 'o': 'ãŠ',
            
            # K-row
            'ka': 'ã‹', 'ki': 'ã', 'ku': 'ã', 'ke': 'ã‘', 'ko': 'ã“',
            'kya': 'ãã‚ƒ', 'kyu': 'ãã‚…', 'kyo': 'ãã‚‡',
            
            # S-row
            'sa': 'ã•', 'shi': 'ã—', 'su': 'ã™', 'se': 'ã›', 'so': 'ã',
            'sha': 'ã—ã‚ƒ', 'shu': 'ã—ã‚…', 'sho': 'ã—ã‚‡',
            
            # T-row
            'ta': 'ãŸ', 'chi': 'ã¡', 'tsu': 'ã¤', 'te': 'ã¦', 'to': 'ã¨',
            'cha': 'ã¡ã‚ƒ', 'chu': 'ã¡ã‚…', 'cho': 'ã¡ã‚‡',
            
            # N-row
            'na': 'ãª', 'ni': 'ã«', 'nu': 'ã¬', 'ne': 'ã­', 'no': 'ã®',
            'nya': 'ã«ã‚ƒ', 'nyu': 'ã«ã‚…', 'nyo': 'ã«ã‚‡',
            
            # H-row
            'ha': 'ã¯', 'hi': 'ã²', 'fu': 'ãµ', 'he': 'ã¸', 'ho': 'ã»',
            'hya': 'ã²ã‚ƒ', 'hyu': 'ã²ã‚…', 'hyo': 'ã²ã‚‡',
            
            # M-row
            'ma': 'ã¾', 'mi': 'ã¿', 'mu': 'ã‚€', 'me': 'ã‚', 'mo': 'ã‚‚',
            'mya': 'ã¿ã‚ƒ', 'myu': 'ã¿ã‚…', 'myo': 'ã¿ã‚‡',
            
            # Y-row
            'ya': 'ã‚„', 'yu': 'ã‚†', 'yo': 'ã‚ˆ',
            
            # R-row
            'ra': 'ã‚‰', 'ri': 'ã‚Š', 'ru': 'ã‚‹', 're': 'ã‚Œ', 'ro': 'ã‚',
            'rya': 'ã‚Šã‚ƒ', 'ryu': 'ã‚Šã‚…', 'ryo': 'ã‚Šã‚‡',
            
            # W-row
            'wa': 'ã‚', 'wo': 'ã‚’', 'n': 'ã‚“',
            
            # G-row
            'ga': 'ãŒ', 'gi': 'ãŽ', 'gu': 'ã', 'ge': 'ã’', 'go': 'ã”',
            'gya': 'ãŽã‚ƒ', 'gyu': 'ãŽã‚…', 'gyo': 'ãŽã‚‡',
            
            # Z-row
            'za': 'ã–', 'ji': 'ã˜', 'zu': 'ãš', 'ze': 'ãœ', 'zo': 'ãž',
            'ja': 'ã˜ã‚ƒ', 'ju': 'ã˜ã‚…', 'jo': 'ã˜ã‚‡',
            
            # D-row
            'da': 'ã ', 'di': 'ã¢', 'du': 'ã¥', 'de': 'ã§', 'do': 'ã©',
            
            # B-row
            'ba': 'ã°', 'bi': 'ã³', 'bu': 'ã¶', 'be': 'ã¹', 'bo': 'ã¼',
            'bya': 'ã³ã‚ƒ', 'byu': 'ã³ã‚…', 'byo': 'ã³ã‚‡',
            
            # P-row
            'pa': 'ã±', 'pi': 'ã´', 'pu': 'ã·', 'pe': 'ãº', 'po': 'ã½',
            'pya': 'ã´ã‚ƒ', 'pyu': 'ã´ã‚…', 'pyo': 'ã´ã‚‡',
        }
    
    def romaji_to_hiragana(self, romaji: str) -> str:
        """Convert romaji to hiragana"""
        result = []
        i = 0
        romaji = romaji.lower()
        
        while i < len(romaji):
            # Try 3-char match first
            if i + 3 <= len(romaji):
                three = romaji[i:i+3]
                if three in self.romaji_map:
                    result.append(self.romaji_map[three])
                    i += 3
                    continue
            
            # Try 2-char match
            if i + 2 <= len(romaji):
                two = romaji[i:i+2]
                if two in self.romaji_map:
                    result.append(self.romaji_map[two])
                    i += 2
                    continue
            
            # Try 1-char match
            one = romaji[i]
            if one in self.romaji_map:
                result.append(self.romaji_map[one])
            else:
                result.append(one)  # Keep as-is if not found
            i += 1
        
        return ''.join(result)
    
    def generate_common_words(self):
        """Generate common Japanese word examples"""
        print("ðŸ“ Generating common word examples...")
        
        # Common words with romaji, hiragana, and kanji
        common_words = [
            # Greetings
            ('konnichiwa', 'ã“ã‚“ã«ã¡ã¯', ['ã“ã‚“ã«ã¡ã¯', 'ä»Šæ—¥ã¯']),
            ('arigatou', 'ã‚ã‚ŠãŒã¨ã†', ['ã‚ã‚ŠãŒã¨ã†', 'æœ‰é›£ã†', 'æœ‰ã‚Šé›£ã†']),
            ('ohayou', 'ãŠã¯ã‚ˆã†', ['ãŠã¯ã‚ˆã†', 'ãŠæ—©ã†']),
            ('konbanwa', 'ã“ã‚“ã°ã‚“ã¯', ['ã“ã‚“ã°ã‚“ã¯', 'ä»Šæ™©ã¯']),
            ('sayonara', 'ã•ã‚ˆãªã‚‰', ['ã•ã‚ˆãªã‚‰', 'å·¦æ§˜ãªã‚‰']),
            ('sumimasen', 'ã™ã¿ã¾ã›ã‚“', ['ã™ã¿ã¾ã›ã‚“', 'æ¸ˆã¿ã¾ã›ã‚“']),
            
            # Common nouns
            ('nihongo', 'ã«ã»ã‚“ã”', ['æ—¥æœ¬èªž', 'ã«ã»ã‚“ã”']),
            ('nihon', 'ã«ã»ã‚“', ['æ—¥æœ¬', 'ã«ã»ã‚“']),
            ('tokyo', 'ã¨ã†ãã‚‡ã†', ['æ±äº¬', 'ã¨ã†ãã‚‡ã†']),
            ('sensei', 'ã›ã‚“ã›ã„', ['å…ˆç”Ÿ', 'ã›ã‚“ã›ã„']),
            ('gakkou', 'ãŒã£ã“ã†', ['å­¦æ ¡', 'ãŒã£ã“ã†']),
            ('tomodachi', 'ã¨ã‚‚ã ã¡', ['å‹é”', 'ã¨ã‚‚ã ã¡']),
            
            # Pronouns
            ('watashi', 'ã‚ãŸã—', ['ç§', 'ã‚ãŸã—']),
            ('anata', 'ã‚ãªãŸ', ['ã‚ãªãŸ', 'è²´æ–¹']),
            ('kare', 'ã‹ã‚Œ', ['å½¼', 'ã‹ã‚Œ']),
            ('kanojo', 'ã‹ã®ã˜ã‚‡', ['å½¼å¥³', 'ã‹ã®ã˜ã‚‡']),
            
            # Verbs
            ('taberu', 'ãŸã¹ã‚‹', ['é£Ÿã¹ã‚‹', 'ãŸã¹ã‚‹']),
            ('nomu', 'ã®ã‚€', ['é£²ã‚€', 'ã®ã‚€']),
            ('iku', 'ã„ã', ['è¡Œã', 'ã„ã']),
            ('kuru', 'ãã‚‹', ['æ¥ã‚‹', 'ãã‚‹']),
            ('miru', 'ã¿ã‚‹', ['è¦‹ã‚‹', 'ã¿ã‚‹']),
            ('kiku', 'ãã', ['èžã', 'è´ã', 'ãã']),
            ('hanasu', 'ã¯ãªã™', ['è©±ã™', 'ã¯ãªã™']),
            ('yomu', 'ã‚ˆã‚€', ['èª­ã‚€', 'ã‚ˆã‚€']),
            ('kaku', 'ã‹ã', ['æ›¸ã', 'ã‹ã']),
            ('benkyou', 'ã¹ã‚“ãã‚‡ã†', ['å‹‰å¼·', 'ã¹ã‚“ãã‚‡ã†']),
            
            # Adjectives
            ('oishii', 'ãŠã„ã—ã„', ['ç¾Žå‘³ã—ã„', 'ãŠã„ã—ã„']),
            ('takai', 'ãŸã‹ã„', ['é«˜ã„', 'é«˜ã„']),
            ('yasui', 'ã‚„ã™ã„', ['å®‰ã„', 'ã‚„ã™ã„']),
            ('ookii', 'ãŠãŠãã„', ['å¤§ãã„', 'ãŠãŠãã„']),
            ('chiisai', 'ã¡ã„ã•ã„', ['å°ã•ã„', 'ã¡ã„ã•ã„']),
            
            # Time
            ('kyou', 'ãã‚‡ã†', ['ä»Šæ—¥', 'ãã‚‡ã†']),
            ('ashita', 'ã‚ã—ãŸ', ['æ˜Žæ—¥', 'ã‚ã—ãŸ']),
            ('kinou', 'ãã®ã†', ['æ˜¨æ—¥', 'ãã®ã†']),
            ('ima', 'ã„ã¾', ['ä»Š', 'ã„ã¾']),
            
            # Numbers
            ('ichi', 'ã„ã¡', ['ä¸€', '1', 'ã„ã¡']),
            ('ni', 'ã«', ['äºŒ', '2', 'ã«']),
            ('san', 'ã•ã‚“', ['ä¸‰', '3', 'ã•ã‚“']),
            ('yon', 'ã‚ˆã‚“', ['å››', '4', 'ã‚ˆã‚“']),
            ('go', 'ã”', ['äº”', '5', 'ã”']),
        ]
        
        for romaji, hiragana, kanji_list in common_words:
            # Add training examples
            # 1. Romaji input â†’ hiragana suggestion
            self.examples.append(f"{romaji} {hiragana}")
            
            # 2. Hiragana â†’ kanji suggestions
            for kanji in kanji_list:
                self.examples.append(f"{hiragana} {kanji}")
            
            # 3. Partial romaji â†’ completion
            for i in range(2, len(romaji)):
                partial = romaji[:i]
                partial_hiragana = self.romaji_to_hiragana(partial)
                self.examples.append(f"{partial} {partial_hiragana}")
        
        print(f"âœ… Generated {len(self.examples)} common word examples")
    
    def generate_katakana_words(self):
        """Generate katakana loanword examples"""
        print("ðŸ“ Generating katakana examples...")
        
        start_count = len(self.examples)
        
        katakana_words = [
            ('amerika', 'ã‚ã‚ã‚Šã‹', 'ã‚¢ãƒ¡ãƒªã‚«'),
            ('koohii', 'ã“ãƒ¼ã²ãƒ¼', 'ã‚³ãƒ¼ãƒ’ãƒ¼'),
            ('terebi', 'ã¦ã‚Œã³', 'ãƒ†ãƒ¬ãƒ“'),
            ('konpyuutaa', 'ã“ã‚“ã´ã‚…ãƒ¼ãŸãƒ¼', 'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼'),
            ('intaanetto', 'ã„ã‚“ãŸãƒ¼ã­ã£ã¨', 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ'),
            ('anime', 'ã‚ã«ã‚', 'ã‚¢ãƒ‹ãƒ¡'),
            ('geemu', 'ã’ãƒ¼ã‚€', 'ã‚²ãƒ¼ãƒ '),
            ('resutoran', 'ã‚Œã™ã¨ã‚‰ã‚“', 'ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³'),
            ('hoteru', 'ã»ã¦ã‚‹', 'ãƒ›ãƒ†ãƒ«'),
            ('takushii', 'ãŸãã—ãƒ¼', 'ã‚¿ã‚¯ã‚·ãƒ¼'),
            ('basu', 'ã°ã™', 'ãƒã‚¹'),
            ('densha', 'ã§ã‚“ã—ã‚ƒ', 'ãƒ‡ãƒ³ã‚·ãƒ£'),
            ('kamera', 'ã‹ã‚ã‚‰', 'ã‚«ãƒ¡ãƒ©'),
            ('pasokon', 'ã±ãã“ã‚“', 'ãƒ‘ã‚½ã‚³ãƒ³'),
            ('sumaho', 'ã™ã¾ã»', 'ã‚¹ãƒžãƒ›'),
        ]
        
        for romaji, hiragana, katakana in katakana_words:
            self.examples.append(f"{romaji} {katakana}")
            self.examples.append(f"{hiragana} {katakana}")
        
        print(f"âœ… Generated {len(self.examples) - start_count} katakana examples")
    
    def generate_from_dictionary(self):
        """Generate examples from existing dictionary data"""
        print("ðŸ“ Processing existing dictionary data...")
        
        dict_file = Path('data/processed/comprehensive_train.txt')
        if not dict_file.exists():
            print("âš ï¸  Dictionary file not found, skipping")
            return
        
        start_count = len(self.examples)
        processed = 0
        
        with open(dict_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or len(line) < 2:
                    continue
                
                # Use dictionary entries as-is for context learning
                self.examples.append(line)
                processed += 1
                
                if processed >= 100000:  # Limit to 100K from dictionary
                    break
        
        print(f"âœ… Added {len(self.examples) - start_count} dictionary examples")
    
    def save_training_data(self):
        """Save generated training data"""
        output_file = self.data_dir / 'ime_training.txt'
        
        print(f"\nðŸ’¾ Saving training data...")
        print(f"   Total examples: {len(self.examples):,}")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            for example in self.examples:
                f.write(example + '\n')
        
        file_size = output_file.stat().st_size / (1024 * 1024)
        print(f"âœ… Saved to: {output_file}")
        print(f"   Size: {file_size:.1f} MB")
        
        # Save statistics
        stats = {
            'total_examples': len(self.examples),
            'file_size_mb': file_size,
            'output_file': str(output_file)
        }
        
        stats_file = self.data_dir / 'ime_stats.json'
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2)
        
        print(f"ðŸ“Š Stats saved to: {stats_file}")
    
    def generate_all(self):
        """Generate all training data"""
        print("="*70)
        print("JAPANESE IME TRAINING DATA GENERATION")
        print("="*70)
        print()
        
        # Generate different types of examples
        self.generate_common_words()
        self.generate_katakana_words()
        self.generate_from_dictionary()
        
        # Save
        self.save_training_data()
        
        print()
        print("="*70)
        print("âœ… IME TRAINING DATA READY!")
        print("="*70)
        print()
        print("Next steps:")
        print("1. Train Japanese model:")
        print("   python scripts/train_multilang.py --language japanese")
        print()
        print("2. Test against IME cases:")
        print("   python scripts/test_japanese_ime.py")
        print()


def main():
    """Main entry point"""
    generator = JapaneseIMEDataGenerator()
    generator.generate_all()


if __name__ == '__main__':
    main()
